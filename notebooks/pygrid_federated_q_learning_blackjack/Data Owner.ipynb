{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6796fda",
   "metadata": {},
   "source": [
    "# Data Owner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a6b6c8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Before running this notebook, run the Data Scientist notebook to host a model in PyGrid.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf803f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "from typing import Any\n",
    "\n",
    "import gym\n",
    "import requests\n",
    "import torch as T\n",
    "from torch import nn\n",
    "from websocket import create_connection\n",
    "\n",
    "from syft import serialize\n",
    "from syft.federated.model_serialization import (\n",
    "    deserialize_model_params,\n",
    "    wrap_model_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5883bf",
   "metadata": {},
   "source": [
    "## Step 1: Specify configuration and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d536b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"q-learning\"\n",
    "VERSION = \"0.0.0\"\n",
    "GRID_ADDRESS = \"localhost:5000\"\n",
    "BLACKJACK_DIMS = (32, 11, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df3db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify(json_data: object) -> str:\n",
    "    return json.dumps(json_data, indent=2).replace(\"\\\\n\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f5c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_params(model: nn.Module, params: list[T.Tensor]) -> None:\n",
    "    for p, p_new in zip(model.parameters(), params):\n",
    "        p.data = p_new.detach().clone().data\n",
    "\n",
    "\n",
    "def calculate_diff(\n",
    "    original_params: list[T.Tensor], trained_params: list[T.Tensor]\n",
    ") -> list[T.Tensor]:\n",
    "    return [old - new for old, new in zip(original_params, trained_params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82964c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_ws_message(grid_address: str, data: object) -> Any:\n",
    "    ws = create_connection(\"ws://\" + grid_address)\n",
    "    ws.send(json.dumps(data))\n",
    "    message = ws.recv()\n",
    "    return json.loads(message)\n",
    "\n",
    "\n",
    "def get_model_params(\n",
    "    grid_address: str, worker_id: str, request_key: str, model_id: str\n",
    ") -> list[T.Tensor]:\n",
    "    get_params = {\n",
    "        \"worker_id\": worker_id,\n",
    "        \"request_key\": request_key,\n",
    "        \"model_id\": model_id,\n",
    "    }\n",
    "    response = requests.get(\n",
    "        f\"http://{grid_address}/model-centric/get-model\", get_params\n",
    "    )\n",
    "    return deserialize_model_params(response.content)\n",
    "\n",
    "\n",
    "def retrieve_model_params(grid_address: str, name: str, version: str) -> list[T.Tensor]:\n",
    "    get_params = {\n",
    "        \"name\": name,\n",
    "        \"version\": version,\n",
    "        \"checkpoint\": \"latest\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(\n",
    "        f\"http://{grid_address}/model-centric/retrieve-model\", get_params\n",
    "    )\n",
    "    return deserialize_model_params(response.content)\n",
    "\n",
    "\n",
    "def send_auth_request(grid_address: str, name: str, version: str) -> Any:\n",
    "    message = {\n",
    "        \"type\": \"model-centric/authenticate\",\n",
    "        \"data\": {\n",
    "            \"model_name\": name,\n",
    "            \"model_version\": version,\n",
    "        },\n",
    "    }\n",
    "    return send_ws_message(grid_address, message)\n",
    "\n",
    "\n",
    "def send_cycle_request(\n",
    "    grid_address: str, name: str, version: str, worker_id: str\n",
    ") -> Any:\n",
    "    message = {\n",
    "        \"type\": \"model-centric/cycle-request\",\n",
    "        \"data\": {\n",
    "            \"worker_id\": worker_id,\n",
    "            \"model\": name,\n",
    "            \"version\": version,\n",
    "            \"ping\": 1,\n",
    "            \"download\": 10000,\n",
    "            \"upload\": 10000,\n",
    "        },\n",
    "    }\n",
    "    return send_ws_message(grid_address, message)\n",
    "\n",
    "\n",
    "def send_diff_report(\n",
    "    grid_address: str, worker_id: str, request_key: str, diff: list[T.Tensor]\n",
    ") -> Any:\n",
    "    serialized_diff = serialize(wrap_model_params(diff)).SerializeToString()\n",
    "    message = {\n",
    "        \"type\": \"model-centric/report\",\n",
    "        \"data\": {\n",
    "            \"worker_id\": worker_id,\n",
    "            \"request_key\": request_key,\n",
    "            \"diff\": base64.b64encode(serialized_diff).decode(\"ascii\"),\n",
    "        },\n",
    "    }\n",
    "    send_ws_message(grid_address, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860247d5",
   "metadata": {},
   "source": [
    "## Step 2: Define the model and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c41735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (current sum, dealer card, usable ace)\n",
    "BlackjackObservation = tuple[int, int, bool]\n",
    "\n",
    "class QLearningAgent(nn.Module):\n",
    "    def __init__(self, alpha: float, gamma: float) -> None:\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # learning rate\n",
    "        self.gamma = gamma  # discount rate\n",
    "        self.network = nn.Linear(32 * 11 * 2 * 2, 1, bias=False)\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "        nn.init.zeros_(self.network.weight)\n",
    "\n",
    "    def act(self, observation: BlackjackObservation) -> int:\n",
    "        output = self.get_q_values_for_observation(observation)\n",
    "        return int(output.argmax())\n",
    "\n",
    "    def get_q_values_for_observation(\n",
    "        self, observation: BlackjackObservation\n",
    "    ) -> T.Tensor:\n",
    "        q_table = self.network.weight.reshape(BLACKJACK_DIMS)\n",
    "        current_sum, dealer_card, usable_ace = observation\n",
    "        return q_table[current_sum][dealer_card][int(usable_ace)]\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        observation: BlackjackObservation,\n",
    "        action: int,\n",
    "        reward: float,\n",
    "        observation_next: BlackjackObservation,\n",
    "    ) -> None:\n",
    "        q_values = self.get_q_values_for_observation(observation)\n",
    "        max_next_q_value = self.get_q_values_for_observation(observation_next).max()\n",
    "        q_values[action] = q_values[action] + self.alpha * (\n",
    "            reward + self.gamma * max_next_q_value - q_values[action]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0095eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(agent: QLearningAgent, environment: gym.Env, train: bool) -> float:\n",
    "    ret = 0.0\n",
    "    observation = environment.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(observation)\n",
    "        observation_next, reward, done, _ = environment.step(action)\n",
    "        ret += reward\n",
    "        if train:\n",
    "            agent.update(observation, action, reward, observation_next)\n",
    "        observation = observation_next\n",
    "\n",
    "    return ret\n",
    "\n",
    "def run_epoch(n_iterations: int, agent: QLearningAgent, train=True):\n",
    "    environment = gym.make(\"Blackjack-v0\")\n",
    "    rets = []\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        ret = run_iteration(agent, environment, train)\n",
    "        rets.append(ret)\n",
    "\n",
    "    return list(agent.parameters()), rets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f45be0",
   "metadata": {},
   "source": [
    "## Step 3: Authenticate for cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f57b001e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auth_response = send_auth_request(GRID_ADDRESS, NAME, VERSION)\n",
    "worker_id = auth_response[\"data\"][\"worker_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c5a95",
   "metadata": {},
   "source": [
    "## Step 4: Make cycle request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2014a035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cycle_response = send_cycle_request(GRID_ADDRESS, NAME, VERSION, worker_id)\n",
    "request_key = cycle_response[\"data\"][\"request_key\"]\n",
    "model_id = cycle_response[\"data\"][\"model_id\"]\n",
    "client_config = cycle_response[\"data\"][\"client_config\"]\n",
    "alpha = client_config[\"alpha\"]\n",
    "gamma = client_config[\"gamma\"]\n",
    "n_train_iterations = client_config[\"n_train_iterations\"]\n",
    "n_test_iterations = client_config[\"n_test_iterations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325b18a",
   "metadata": {},
   "source": [
    "## Step 5: Download the model parameters and set local model parameters accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea984505",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_params = get_model_params(GRID_ADDRESS, worker_id, request_key, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb5addf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_agent = QLearningAgent(alpha=alpha, gamma=gamma)\n",
    "set_params(local_agent, downloaded_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b035af",
   "metadata": {},
   "source": [
    "## Step 6: Train the local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96b7db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training performance: -0.2056\n"
     ]
    }
   ],
   "source": [
    "_, pre_rets = run_epoch(n_test_iterations, local_agent, train=False)\n",
    "print(f\"Pre-training performance: {sum(pre_rets) / n_test_iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61aa415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_params, _ = run_epoch(n_train_iterations, local_agent, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ed8342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-training performance: -0.1172\n"
     ]
    }
   ],
   "source": [
    "_, post_rets = run_epoch(n_test_iterations, local_agent, train=False)\n",
    "print(f\"Post-training performance: {sum(post_rets) / n_test_iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b19073",
   "metadata": {},
   "source": [
    "## Step 7: Calculate and send back the diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67b1757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = calculate_diff(downloaded_params, trained_params)\n",
    "send_diff_report(GRID_ADDRESS, worker_id, request_key, diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745c5d3",
   "metadata": {},
   "source": [
    "## Step 8: Test updated remote model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2e33aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated model performance: -0.1336\n"
     ]
    }
   ],
   "source": [
    "new_model_params = retrieve_model_params(GRID_ADDRESS, NAME, VERSION)\n",
    "set_params(local_agent, new_model_params)\n",
    "\n",
    "_, updated_rets = run_epoch(n_test_iterations, local_agent, train=False)\n",
    "print(f\"Updated model performance: {sum(updated_rets) / n_test_iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb063b68",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "You can re-run this notebook to simulate multiple data owners contributing to the federated learning process.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877c10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
